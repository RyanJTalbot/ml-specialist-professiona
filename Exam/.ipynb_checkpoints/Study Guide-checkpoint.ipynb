{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52e6b35",
   "metadata": {},
   "source": [
    "# Study Guide ML-Specialist "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ece1d68",
   "metadata": {},
   "source": [
    "## Section 2 â€“ Exploratory Data Analysis including data preparation\n",
    "\n",
    "### 2.1. Identify the methods used to clean, label, and anonymize data\n",
    "\n",
    "### SUBTASKS:\n",
    "- 2.1.1. Clean data\n",
    "    - 2.1.1.1. Fill or drop missing values\n",
    "    - 2.1.1.2. Remove duplicate rows\n",
    "    - 2.1.1.3. Remove outliers\n",
    "    - 2.1.1.4. Converting data types\n",
    "    - 2.1.1.5. Data normalization\n",
    "    \n",
    "    \n",
    "- 2.1.2. Label data\n",
    "    - 2.1.2.1. Understand the benefits and challenges to labeling data\n",
    "    - 2.1.2.2. Explain data labeling approaches\n",
    "    \n",
    "    \n",
    "- 2.1.3. Anonymize data\n",
    "    \n",
    "REFERENCES:\n",
    "- https://www.ibm.com/garage/method/practices/reason/prepare-data-for-machine-learning/\n",
    "- https://www.ibm.com/garage/method/practices/code/data-preparation-ai-data-science/\n",
    "- https://www.ibm.com/cloud/learn/data-labeling\n",
    "- https://dataplatform.cloud.ibm.com/docs/content/wsj/governance/dmg22.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96189e4",
   "metadata": {},
   "source": [
    "## 2.1.1 Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f0853",
   "metadata": {},
   "source": [
    "### 2.1.1.1. Fill or drop missing values\n",
    "\n",
    "- Remove missing values\n",
    "    - `DataFrame.dropna([axis, how, thresh, ...])`\n",
    "\n",
    "\n",
    "- Fill NA/NaN values using the specified method.\n",
    "    - `DataFrame.fillna([value, method, axis, ...])`\n",
    "\t\n",
    "    \n",
    "- Detect missing values.\n",
    "    - `DataFrame.isna()`\n",
    "\t\n",
    "    \n",
    "- Replace values given in to_replace with value.\t\n",
    "    - `DataFrame.replace([to_replace, value, ...])`\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5bd7a8",
   "metadata": {},
   "source": [
    "### 2.1.1.2. Remove duplicate rows\n",
    "\n",
    "- Return DataFrame with duplicate rows removed.\n",
    "    - `new_df = df.drop_duplicates(keep=False, inplace=false)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f854269",
   "metadata": {},
   "source": [
    "### 2.1.1.3. Remove outliers\n",
    "\n",
    "#### various ways of outlier detection:\n",
    "- Z-Score\n",
    "    - A z-score simply tells you how many standard deviations away an individual data value falls from the mean.\n",
    "    \n",
    "\n",
    "- IQR-distance from Median\n",
    "    - Interquartile range. The IQR describes the middle 50% of values when ordered from lowest to highest. To find the interquartile range (IQR), first find the median (middle value) of the lower and upper half of the data. These values are quartile 1 (Q1) and quartile 3 (Q3). The IQR is the difference between Q3 and Q1.\n",
    "    \n",
    "    - sklearn's RobustScaler \n",
    "        - Scale features using statistics that are robust to outliers. This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f75b80",
   "metadata": {},
   "source": [
    "### 2.1.1.4. Converting data types\n",
    "\n",
    "When working iwth missing <b>Numerical</b> values:\n",
    "- dropna()\n",
    "    - `df.dropna(subset=['price'])`\n",
    "\n",
    "\n",
    "- drop()\n",
    "    - `df.drop('price', axis=1)`\n",
    "\n",
    "\n",
    "- fillna()\n",
    "    - `median = df['price'].median()\n",
    "      df['price'].fillna(median, inplace=True)`\n",
    "      \n",
    "      \n",
    "- scikit-learn `SimpleImputer`\n",
    "    \n",
    "    `from sklearn.impute import SimpleImputer\n",
    "    imputer = SimpleImputer(strategy='median')`\n",
    "    \n",
    "    `price_num = df.drop('price', axis=1)\n",
    "    imputer.fit(price_num)`\n",
    "    \n",
    "    `X = imputer.transform(price_num)`\n",
    "    \n",
    "    `transform_df = pd.DataFrame(X, columns=price_num.columns, index=price_num.index`\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4bdd4",
   "metadata": {},
   "source": [
    "When working iwth missing <b>Text</b> and <b>Categorica;</b> attributes:\n",
    "\n",
    "\n",
    "- Ordinal Encoding using sci-kit learn `OrdinalEncoder`\n",
    "\n",
    "    `wrd_cat = df[['words']]`\n",
    "\n",
    "    `from sklearn.preprocessing import OrdinalEncoder\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    wrd_cat_encoded = ordinal_encoder.fit_transform(wrd_cat)`\n",
    "    \n",
    "- one-hot encoding using sci-kit learn OneHotEncoder\n",
    "\n",
    "    `wrd_cat = df[['words']]`\n",
    "\n",
    "    `from sklearn.preprocessing import OneHotEncoder\n",
    "    cat_encoder = OneHotEncoder()\n",
    "    wrd_cat_1hot = cat_encoder.fit_transform(wrd_cat)`\n",
    "    \n",
    "    the result is a SciPy sparse matrix. To convert it to a (dense) NumPy array use `toarray()`\n",
    "    \n",
    "    `wrd_cat_1hot.toarray()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c1a64",
   "metadata": {},
   "source": [
    "### 2.1.1.5. Data normalization\n",
    "\n",
    "- Min-max scaling (aka normalization) is the simplest form of feature scaling. Values are shifted and rescaled so that they end up ranging from 0 to 1. \n",
    "    - scikit-learn MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a8f01",
   "metadata": {},
   "source": [
    "## 2.1.2. Label data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0344cab6",
   "metadata": {},
   "source": [
    "### 2.1.2.1. Understand the benefits and challenges to labeling data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e40add",
   "metadata": {},
   "source": [
    "2.2. Visualize data\n",
    "SUBTASKS:\n",
    "2.2.1. Choose the column(s) from your dataset to be visualized\n",
    "2.2.2. Identify what the visualization should describe about the column(s)\n",
    "2.2.2.1. Distribution\n",
    "2.2.2.2. Correlation\n",
    "2.2.2.3. Comparison\n",
    "2.2.2.4. Time Series\n",
    "2.2.3. Select a type of chart based on the descriptive need\n",
    "2.2.3.1. Histogram/Box plot/Violin plot\n",
    "2.2.3.2. Scatterplot/Heatmap\n",
    "2.2.3.3. Bar chart\n",
    "2.2.3.4. Line plot\n",
    "2.2.4. Select a library or tool for visualization\n",
    "2.2.4.1. Matplotlib\n",
    "2.2.4.2. Seaborn\n",
    "2.2.4.3. Bokeh\n",
    "2.2.4.4. Plotly\n",
    "2.2.5. Plot the visualization\n",
    "REFERENCES:\n",
    "https://seaborn.pydata.org/introduction.html\n",
    "https://matplotlib.org/stable/tutorials/introductory/usage.html#sphx-glr-tutorials-introductory-usage-py\n",
    "https://docs.bokeh.org/en/latest/docs/first_steps.html\n",
    "https://plotly.com/python/\n",
    "https://learn.ibm.com/course/view.php?id=8794\n",
    "https://learning.oreilly.com/library/view/statistics-in-a/9781449361129/ Chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d5b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
